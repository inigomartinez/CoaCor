#!/bin/sh

python preprocess.py -token_src ../../data/source/java_index_to_tokenized_code.pkl -token_tgt ../../data/source/java_index_to_tokenized_qt.pkl -split_indices ../../data/source/split_indices_java_cleaned.pkl -src_word2id ../../data/source/java.code.vocab.pkl -src_seq_length 120 -tgt_seq_length 20 -tgt_word2id ../../data/source/java.qt.vocab.pkl -save_data dataset/train_qt_new_cleaned/java.processed_all --DEV_src ../../data/source/codenn_java/codenn.dev.ix_to_tokenized_code.pkl --DEV_tgt ../../data/source/codenn_java/codenn.dev.ix_to_tokenized_qt.pkl --DEV_indices ../../data/source/codenn_java/codenn.dev.qid_cid_pair.gen.dataset.pkl --EVAL_src ../../data/source/codenn_java/codenn.eval.ix_to_tokenized_code.pkl --EVAL_tgt ../../data/source/codenn_java/codenn.eval.ix_to_tokenized_qt.pkl --EVAL_indices ../../data/source/codenn_java/codenn.eval.qid_cid_pair.gen.dataset.pkl -word_vec_size 256 > log_qt_new_cleaned/log.java.preprocess
